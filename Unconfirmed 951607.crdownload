# -*- coding: utf-8 -*-
"""AdvClass_TeamND2_Draft_Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Lob_ezRWUzmhq1_4_HC_Ko29uj2cfHb

# Classification Predict - Climate Change Belief Analysis Challenge
© Explore Data Science Academy

---
### Honour Code

I {**#Team_ND2**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).

Non-compliance with the honour code constitutes a material breach of contract.

<a id="cont"></a>

## Table of Contents

#### Section 1: Data Pre-processing

<a href=#one>1.1 Importing Packages</a>

<a href=#two>1.2 Loading Data</a>

<a href=#three>1.3 Exploratory Data Analysis (EDA)</a>

<a href=#four>1.4 Data Engineering</a>

#### Section 2: Model Development and Analysis

<a href=#five>2.1 Modeling</a>

<a href=#six>2.2 Model Performance</a>

#### Section 3: Model Explanation and Conclusions

<a href=#seven>3.1 Model Explanations</a>

<a href=#seven>3.2 Conclusions</a>

# Introduction
Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.

With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.

Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies. This Notebook has been so adapted and developed by **TeamND2** - a group of six students from the July 2022 cohort of the Explore Ai Academy **Data Science** course. We are:

 > David Mugambi <br>
 > Gavriel Leibovitz <br>
 > Josiah Aramide <br>
 > Aniedi Oboho-Etuk <br>
 > Joy Obukohwo <br>
 > Marvellous Eromosele <br>

### Problem Statement

The scenario involves

### Objectives

TeamND2 seeks to achieve the following objectives for the project brief:

- 1. analyse the supplied data;
- 2. identify xxx;
- 3. de

# Section 1: Data Pre-processing

This section describes steps for importing packages, loading the two datasets - train and test datasets, conducting the exploratory data analysis (EDA) and implementing data engineering.

<a id="one"></a>
## 1.1 Importing Packages
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Importing Packages ⚡ |
| :--------------------------- |
| Below are the libraries imported for use in this project. The libraries include  |

---
"""

# Commented out IPython magic to ensure Python compatibility.
# Libraries for data loading, data manipulation and data visulisation
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

# Libraries for data preparation and model building
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import mutual_info_regression #determine mutual info
from sklearn.preprocessing import StandardScaler # for standardization
from sklearn.model_selection import train_test_split
from sklearn import metrics
import math
import time
import datetime as dt
from sklearn.metrics import r2_score

"""Green Energy!!! Is it just a buzz? Is there a thing as Green-House Gas or Global Warming? Today we find out what Twitter users think!

<a id="two"></a>
## 1.2 Loading the Data
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Loading the data ⚡ |
| :--------------------------- |
| In this section, we load the data from the . |

---
"""

from google.colab import files
uploaded = files.upload()

import io
df_train = pd.read_csv(io.BytesIO(uploaded['train.csv']))
df_train = pd.read_csv(io.BytesIO(uploaded['test_with_no_labels.csv']))
# Dataset is now stored in a Pandas Dataframe

# View top of dataset

df_train.head()

# view bottom of dataset

df_train.tail()

# View rows
df_train.index # we have 15,819 rows of data

# view columns

df_train.columns



"""<a id="three"></a>
## 1.3 Exploratory Data Analysis (EDA)
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Exploratory data analysis ⚡ |
| :--------------------------- |
| In this section, we perform an in-depth analysis of all the features |

---
"""

# Dataset Matrix
df_train.shape

# Data Statistics
df_train.describe().T

# Data Types and Non-null count 
df_train.info()

"""### No Null Rows in Columns"""

# Check for null values 
def null_cols(df):
    features_with_nulls = []
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            features_with_nulls.append((col, df[col].isnull().sum()))
            
        
    return features_with_nulls

# Call the function
null_cols(df_train)

"""### Function method of extracting usernames using list comprehension lambda function"""

# # Extract Username. 
#Function method of extracting usernames using list comprehension lambda function
def extract_username(df):
    import re
    copy_df = df.copy()
    #copy_df['message'] = copy_df['message'].values.astype(str)
    copy_df['Username'] = list(map(lambda x: re.findall('(@[a-zA-Z]+\w+)', x), copy_df['message']))
    return copy_df

extract_username(df_train)

# Extract Username. 
# Using regex methods
import re

#df_train['message'] = df_train['message'].values.astype(str)
df_train['Username'] = df_train['message'].str.extract('(\@[a-zA-Z]+\w+)')
df_train

copy_df = df_train.copy()

copy_df['Username'] = list(map(lambda x: re.findall('(@[a-zA-Z]+\w+)', x), copy_df['message'].astype(str)))

copy_df

"""<a id="four"></a>
## 1.4 Data Engineering
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Data engineering ⚡ |
| :--------------------------- |
| In this section we conduct our feature engineering to: clean the dataset, and create new features - as identified in the EDA phase. Later, we initiate some ... |

---
"""



"""# Section 2: Model Development and Analysis

This section describes

# <a id="five"></a>
## 2.1 Modelling
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Modelling ⚡ |
| :--------------------------- |
| In this section, the team developed some ... Our choice of models include:

- M
- L
- Support Vector Machines
- DecisionTrees
- RandomForest
---
We continue to explore some ... 

Also, in this stage...
"""



"""<a id="six"></a>
## 2.2 Model Performance
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Model performance ⚡ |
| :--------------------------- |
| In this section we will compare the relative performance of the various ... |

---
We will use the following
"""



"""# Section 3: Model Explanations and Conclusions

This section describes

<a id="seven"></a>
## 3.1 Model Explanation
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Model explanation ⚡ |
| :--------------------------- |
| In this section, we discuss how the best performing model works in a simple way ...|

---
"""



"""<a id="seven"></a>
## 3.2 Conclusions
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Model explanation ⚡ |
| :--------------------------- |
| In this section, we discuss how the best performing model works in a simple way ...|

---
"""

